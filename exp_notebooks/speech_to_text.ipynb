{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech-to-Text API Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import speech_v1p1beta1 as speech\n",
    "from google.cloud import storage\n",
    "\n",
    "import spacy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Reshape, Bidirectional\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tqdm import tqdm \n",
    "\n",
    "import gensim.downloader as api\n",
    "\n",
    "import string\n",
    "import json \n",
    "import re\n",
    "\n",
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:/Users/ekin/Downloads/hack.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Client Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function to test credentials\n",
    "'''\n",
    "def implicit():\n",
    "    from google.cloud import storage\n",
    "\n",
    "    # If you don't specify credentials when constructing the client, the\n",
    "    # client library will look for credentials in the environment.\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    # Make an authenticated API request\n",
    "    buckets = list(storage_client.list_buckets())\n",
    "    print(buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "implicit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[alternatives {\n",
      "  transcript: \"how old is the Brooklyn Bridge\"\n",
      "  confidence: 0.9823954\n",
      "}\n",
      "language_code: \"en-us\"\n",
      "]\n",
      "Transcript: how old is the Brooklyn Bridge\n",
      "Confidence: 0.9823954105377197\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Test speech client and transcription API on a sample audio file. \n",
    "'''\n",
    "# Instantiates a client\n",
    "client = speech.SpeechClient()\n",
    "\n",
    "# The name of the audio file to transcribe\n",
    "gcs_uri = \"gs://cloud-samples-data/speech/brooklyn_bridge.raw\"\n",
    "\n",
    "audio = speech.RecognitionAudio(uri=gcs_uri)\n",
    "\n",
    "config = speech.RecognitionConfig(\n",
    "    encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "    sample_rate_hertz=16000,\n",
    "    language_code=\"en-US\",\n",
    ")\n",
    "\n",
    "# Detects speech in the audio file\n",
    "response = client.recognize(config=config, audio=audio)\n",
    "\n",
    "print(response.results)\n",
    "\n",
    "for result in response.results:\n",
    "    print(\"Transcript: {}\".format(result.alternatives[0].transcript))\n",
    "    print(\"Confidence: {}\".format(result.alternatives[0].confidence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcribing Long Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_gcs(gcs_uri):\n",
    "    \"\"\"Asynchronously transcribes the audio file specified by the gcs_uri.\"\"\"\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    audio = speech.RecognitionAudio(uri=gcs_uri)\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.FLAC,\n",
    "        sample_rate_hertz=48000,\n",
    "        audio_channel_count=2,\n",
    "        language_code=\"en-US\",\n",
    "        enable_word_time_offsets=True, \n",
    "        enable_word_confidence=True,\n",
    "    )\n",
    "\n",
    "    operation = client.long_running_recognize(config=config, audio=audio)\n",
    "\n",
    "    print(\"Waiting for operation to complete...\")\n",
    "    response = operation.result(timeout=90)\n",
    "\n",
    "    # Each result is for a consecutive portion of the audio. Iterate through\n",
    "    # them to get the transcripts for the entire audio file.\n",
    "    for result in response.results:\n",
    "        # The first alternative is the most likely one for this portion.\n",
    "        alternative = result.alternatives[0]\n",
    "        print(u\"Transcript: {}\".format(result.alternatives[0].transcript))\n",
    "        print(\"Confidence: {}\".format(result.alternatives[0].confidence))\n",
    "        \n",
    "    return response.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for operation to complete...\n",
      "Transcript: I'm going to test maybe that's a bit different interesting absolutely totally no way\n",
      "Confidence: 0.9492603540420532\n"
     ]
    }
   ],
   "source": [
    "example_gcs_uri = \"gs://hack_the_ne/hmms.flac\"\n",
    "results = transcribe_gcs(example_gcs_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcript Processing Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = results[0].alternatives[0]\n",
    "transcript = result.transcript\n",
    "words = result.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm going to test maybe that's a bit different interesting absolutely totally no way\n"
     ]
    }
   ],
   "source": [
    "print(transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clarity\n",
    "Measurement of how understandable your speech is. Based on the confidence of the overall transcription. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clarity = result.confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brevity\n",
    "Count the number of filler_words or hedging language phrases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function returns a count of how many times \n",
    "each phrase in the `phrases` list is in the \n",
    "`transcript` string. \n",
    "'''\n",
    "def count_phrases(transcript, phrases, return_phrase_counts=True): \n",
    "    space_transcript = ' ' + transcript + ' '\n",
    "    phrase_counts = {}\n",
    "    all_counts = 0 \n",
    "    for phrase in phrases: \n",
    "        space_phrase = ' ' + phrase + ' '\n",
    "        count = space_transcript.count(space_phrase)\n",
    "        if count > 0: \n",
    "            phrase_counts[phrase] = count\n",
    "            all_counts = all_counts + count\n",
    "    \n",
    "    if return_phrase_counts: \n",
    "        return phrase_counts, all_counts # Return the counts for each filler phrase\n",
    "    else:\n",
    "        return all_counts # Only return the total number of counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filler_words = [\n",
    "    'like', \n",
    "    'I mean',\n",
    "    'you know', \n",
    "    'so', \n",
    "    'well', \n",
    "    'you see', \n",
    "]\n",
    "\n",
    "hedging_language = [\n",
    "    'kind of', \n",
    "    'I think', \n",
    "    'maybe',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'like': 1, 'so': 1}\n"
     ]
    }
   ],
   "source": [
    "test_string = \"so I think I will begin with this like kind of interesting thing maybe\"\n",
    "filler_phrase_counts, filler_all_counts = count_phrases(test_string, filler_words)\n",
    "print(filler_phrase_counts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kind of': 1, 'I think': 1, 'maybe': 1}\n"
     ]
    }
   ],
   "source": [
    "hedging_phrase_counts, hedging_all_counts = count_phrases(test_string, hedging_language)\n",
    "print(hedging_phrase_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cadence\n",
    "Counting the number of words spoken every second. \n",
    "\n",
    "* Average is 130 words per minute | 2.166 words per second (avg)\n",
    "* Takes us around 0.46 seconds to speak one word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Compute the total duration of the speech in seconds, given\n",
    "the dict of words. \n",
    "'''\n",
    "def speech_time(words): \n",
    "    first_word = words[0]\n",
    "    last_word = words[-1]\n",
    "    \n",
    "    start_time = first_word.start_time.total_seconds()\n",
    "    end_time = last_word.end_time.total_seconds()\n",
    "    \n",
    "    return end_time - start_time\n",
    "\n",
    "'''\n",
    "Computes the number of words spoken in the speech per \n",
    "second, given `words` as a dict. \n",
    "'''\n",
    "def words_per_second(words, time): \n",
    "    return len(words) / time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time:  15.3\n",
      "Pace (words / second):  0.9150326797385621\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Perform actual computations\n",
    "'''\n",
    "total_time = speech_time(words)\n",
    "pace = words_per_second(words, total_time)\n",
    "\n",
    "print('Total Time: ', total_time)\n",
    "print('Pace (words / second): ', pace) # slower than average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Compute the number of seconds for each word in `words`\n",
    "'''\n",
    "\n",
    "def seconds_per_word(words, verbose=False):\n",
    "    word_times = {}\n",
    "    for word_info in words:\n",
    "        word = word_info.word\n",
    "        start_time = word_info.start_time.total_seconds()\n",
    "        end_time = word_info.end_time.total_seconds()\n",
    "        confidence = word_info.confidence\n",
    "\n",
    "        if verbose: \n",
    "            print(\n",
    "                f\"{word}, start_time: {start_time}, end_time: {end_time}, confidence: {confidence}\"\n",
    "            )\n",
    "\n",
    "        time_of_word = round(end_time - start_time, 3)\n",
    "        word_times[word] = time_of_word\n",
    "        \n",
    "    return word_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm, start_time: 1.3, end_time: 1.9, confidence: 0.9876290559768677\n",
      "going, start_time: 1.9, end_time: 2.1, confidence: 0.9876290559768677\n",
      "to, start_time: 2.1, end_time: 2.2, confidence: 0.9876290559768677\n",
      "test, start_time: 2.2, end_time: 2.5, confidence: 1.0\n",
      "maybe, start_time: 2.5, end_time: 4.7, confidence: 0.9239681959152222\n",
      "that's, start_time: 4.7, end_time: 5.1, confidence: 0.9249534010887146\n",
      "a, start_time: 5.1, end_time: 5.4, confidence: 0.9668338894844055\n",
      "bit, start_time: 5.4, end_time: 5.6, confidence: 0.9876290559768677\n",
      "different, start_time: 5.6, end_time: 6.2, confidence: 1.0\n",
      "interesting, start_time: 6.2, end_time: 13.7, confidence: 0.8979593515396118\n",
      "absolutely, start_time: 13.7, end_time: 14.9, confidence: 0.9249765872955322\n",
      "totally, start_time: 14.9, end_time: 15.2, confidence: 0.9876290559768677\n",
      "no, start_time: 15.2, end_time: 16.4, confidence: 0.8444064855575562\n",
      "way, start_time: 16.4, end_time: 16.6, confidence: 0.8684027194976807\n",
      "{\"I'm\": 0.6, 'going': 0.2, 'to': 0.1, 'test': 0.3, 'maybe': 2.2, \"that's\": 0.4, 'a': 0.3, 'bit': 0.2, 'different': 0.6, 'interesting': 7.5, 'absolutely': 1.2, 'totally': 0.3, 'no': 1.2, 'way': 0.2}\n"
     ]
    }
   ],
   "source": [
    "word_times = seconds_per_word(words, verbose=True)\n",
    "# word_times = {k: v for k, v in sorted(word_times.items(), key=lambda item: item[1])} # sorted\n",
    "print(word_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO-DO: Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: plot each word on a histogram and also plot an average line \n",
    "# simpler, just count the number of words that are greater than average, and compare\n",
    "def classify_pauses(baseline_time): \n",
    "    normal_words = {}\n",
    "    delayed_words = {}\n",
    "    avg_time = 0.46\n",
    "    for word, time in word_times.items(): \n",
    "        if time > avg_time: \n",
    "            delayed_words[word] = time\n",
    "        else:\n",
    "            normal_words[word] = time\n",
    "    return normal_words, delayed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal words:  {'going': 0.2, 'to': 0.1, 'test': 0.3, \"that's\": 0.4, 'a': 0.3, 'bit': 0.2, 'totally': 0.3, 'way': 0.2}\n",
      "Delayed words:  {\"I'm\": 0.6, 'maybe': 2.2, 'different': 0.6, 'interesting': 7.5, 'absolutely': 1.2, 'no': 1.2}\n"
     ]
    }
   ],
   "source": [
    "avg_time = 0.5 # half a second per word on avg. \n",
    "normal_words, delayed_words = classify_pauses(avg_time)\n",
    "print('Normal words: ', normal_words)\n",
    "print('Delayed words: ', delayed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strong Vocabulary (Passion/Urgency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noun phrases: ['I', 'no way']\n",
      "Verbs: ['go', 'test']\n",
      "Adjectives: ['different', 'interesting']\n"
     ]
    }
   ],
   "source": [
    "# Analyze syntax\n",
    "noun_phrases = [chunk.text for chunk in doc.noun_chunks]\n",
    "verb_phrases = [chunk.text for chunk in doc.noun_chunks]\n",
    "\n",
    "print(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])\n",
    "print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])\n",
    "print(\"Adjectives:\", [token.lemma_ for token in doc if token.pos_ == \"ADJ\"])\n",
    "\n",
    "# for token in doc: \n",
    "#     print(token.pos_)\n",
    "# Find named entities, phrases and concepts\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: rate the adjectives based on level of neutrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TED Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wv():\n",
    "    # this line of code needs to run asynchronously first\n",
    "    wv = api.load('word2vec-google-news-300')\n",
    "    return wv\n",
    "\n",
    "def create_embedding(transcript, wv):\n",
    "#     print(transcript)\n",
    "    X = []\n",
    "    found_words = []\n",
    "    words = transcript.split()\n",
    "    for word in words: \n",
    "        try:\n",
    "            found_words.append(wv[word])\n",
    "        except: \n",
    "            continue\n",
    "            \n",
    "    embedding = np.asarray(found_words)\n",
    "    mean = np.mean(embedding, axis=0)\n",
    "    mean = mean.tolist()\n",
    "\n",
    "    if type(mean) == list: \n",
    "        X.append(mean)\n",
    "\n",
    "    X = np.array(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_analysis():\n",
    "    wv = load_wv()\n",
    "    embedding = create_embedding(transcript, wv)\n",
    "    \n",
    "    model_filepath = './ted_analysis_model'\n",
    "    model = tf.keras.models.load_model(model_filepath)\n",
    "    \n",
    "    pred = model.predict(embedding)[0]\n",
    "    cols = ['Beautiful', 'Confusing', 'Courageous', 'Funny', 'Informative', 'Ingenious', 'Inspiring', 'Longwinded', 'Unconvincing', 'Fascinating', 'Jaw-dropping', 'Persuasive', 'OK', 'Obnoxious']\n",
    "    \n",
    "    ted_dict = {}\n",
    "    for val, col in zip(pred, cols):\n",
    "        ted_dict[col] = val\n",
    "    return ted_dict # can be converted to a JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ted_dict = perform_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Beautiful': 0.11447036, 'Confusing': 0.10280144, 'Courageous': 0.0026097298, 'Funny': 0.81440914, 'Informative': 0.11125913, 'Ingenious': 0.7225983, 'Inspiring': 0.111739606, 'Longwinded': 0.026772916, 'Unconvincing': 0.09550491, 'Fascinating': 0.8304244, 'Jaw-dropping': 0.35544878, 'Persuasive': 0.0057587028, 'OK': 0.45375717, 'Obnoxious': 0.10564661}\n"
     ]
    }
   ],
   "source": [
    "print(ted_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TED Analysis Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = load_wv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = create_embedding(transcript, wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filepath = './ted_analysis_model'\n",
    "model = tf.keras.models.load_model(model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(embedding)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm going to test maybe that's a bit different interesting absolutely totally no way\n"
     ]
    }
   ],
   "source": [
    "print(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Beautiful', 'Confusing', 'Courageous', 'Funny', 'Informative', 'Ingenious', 'Inspiring', 'Longwinded', 'Unconvincing', 'Fascinating', 'Jaw-dropping', 'Persuasive', 'OK', 'Obnoxious']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Beautiful': 0.11447036, 'Confusing': 0.10280144, 'Courageous': 0.0026097298, 'Funny': 0.81440914, 'Informative': 0.11125913, 'Ingenious': 0.7225983, 'Inspiring': 0.111739606, 'Longwinded': 0.026772916, 'Unconvincing': 0.09550491, 'Fascinating': 0.8304244, 'Jaw-dropping': 0.35544878, 'Persuasive': 0.0057587028, 'OK': 0.45375717, 'Obnoxious': 0.10564661}\n"
     ]
    }
   ],
   "source": [
    "ted_dict = {}\n",
    "for val, col in zip(pred, cols):\n",
    "    ted_dict[col] = val\n",
    "print(ted_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
